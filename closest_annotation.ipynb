{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time\n",
      "2019-02-28 14:13:18.260600\n",
      "test data length:3294\n",
      "Total urls in test:3003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import operator\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import datetime\n",
    "\n",
    "\n",
    "# train_dir_path='/home/irlplab/Documents/Share/Akansha/GoogleNLQ/natural_questions/v1.0/train/'\n",
    "# test_dir_path='/home/irlplab/Documents/Share/Akansha/GoogleNLQ/natural_questions/v1.0/dev/'\n",
    "\n",
    "test_dir_path='/home/irlplab/Documents/Share/Akansha/GoogleNLQ/'\n",
    "# test_dir_path='/home/irlplab/Documents/Share/Akansha/temp/test/'\n",
    "train_dir_path='/home/irlplab/Documents/Share/Akansha/temp/train/'\n",
    "\n",
    "test_data=[]\n",
    "\n",
    "train_data = {}\n",
    "\n",
    "test_url = set()\n",
    "\n",
    "null_obj={\n",
    "        \"candidate_index\": -1,\n",
    "        \"end_byte\": -1,\n",
    "        \"end_token\": -1,\n",
    "        \"start_byte\": -1,\n",
    "        \"start_token\": -1\n",
    "      }\n",
    "\n",
    "\n",
    "beta = 3\n",
    "true_pos=0\n",
    "true_neg=0\n",
    "recall_den=0\n",
    "precision_den=0\n",
    "matched_doc=0\n",
    "\n",
    "no_of_annotators = 5\n",
    "\n",
    "def load_json_multiple(segments):\n",
    "    chunk = \"\"\n",
    "    for segment in segments:\n",
    "        \n",
    "        chunk += segment\n",
    "        try:\n",
    "            yield json.loads(chunk)\n",
    "            chunk = \"\"\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "    json_files = [pos_json for pos_json in os.listdir(test_dir_path) if pos_json.endswith('.jsonl')]\n",
    "    all_data=[]\n",
    "#     print(json_files)\n",
    "    global test_url\n",
    "    for index, js in enumerate(json_files):\n",
    "        with open(os.path.join(test_dir_path, js)) as json_file:\n",
    "            for parsed_json in load_json_multiple(json_file):\n",
    "                \n",
    "                data = {}\n",
    "                data[\"example_id\"]=parsed_json['example_id']\n",
    "                data[\"question_text\"]=parsed_json['question_text']\n",
    "                data[\"annotations\"]=parsed_json['annotations']\n",
    "                data[\"document_url\"]=parsed_json['document_url']\n",
    "                test_url.add(parsed_json['document_url'])\n",
    "                all_data.append(data)\n",
    "                \n",
    "    print(\"test data length:\"+str(len(all_data)))\n",
    "    print(\"Total urls in test:\"+str(len(test_url)))\n",
    "    return all_data\n",
    "\n",
    "def get_annotation_text(ex_obj):\n",
    "    start_token = ex_obj['annotations'][0]['long_answer']['start_token']\n",
    "    end_token = ex_obj['annotations'][0]['long_answer']['end_token']\n",
    "#     print(type(start_token))\n",
    "    text = \"\"\n",
    "    while(start_token <= end_token):\n",
    "        if(ex_obj['document_tokens'][start_token]['html_token'] == False):\n",
    "            text = text+\" \"+ex_obj['document_tokens'][start_token]['token']\n",
    "        start_token = start_token+1\n",
    "    return text\n",
    "    \n",
    "\n",
    "\n",
    "def get_train_data(segments):\n",
    "    \n",
    "    for segment in segments:\n",
    "        global train_data\n",
    "        ex_obj = json.loads(segment)\n",
    "        if(ex_obj['document_url'] in test_url):\n",
    "            \n",
    "            if ex_obj['document_url'] not in train_data:\n",
    "                train_data[ex_obj['document_url']]=[]\n",
    "            \n",
    "            data = {}\n",
    "            data[\"example_id\"]=ex_obj['example_id']\n",
    "            data[\"annotations\"]=ex_obj['annotations'][0]['long_answer']\n",
    "            data[\"text\"]= get_annotation_text(ex_obj)\n",
    "#             print(\"train text::\"+str(data))\n",
    "            if data[\"text\"]:\n",
    "                \n",
    "                train_data[ex_obj['document_url']].append(data)\n",
    "            \n",
    "\n",
    "\n",
    "def create_url_dict():\n",
    "    json_files = [pos_json for pos_json in os.listdir(train_dir_path) if pos_json.endswith('.jsonl')]\n",
    "    for index, js in enumerate(json_files):\n",
    "        with open(os.path.join(train_dir_path, js)) as json_file:\n",
    "            get_train_data(json_file)\n",
    "\n",
    "            \n",
    "def get_closest_document_index(train_vector,query_vector):\n",
    "    \n",
    "    cosine_similarities = linear_kernel(query_vector, train_vector).flatten()\n",
    "    index, value = max(enumerate(cosine_similarities), key=operator.itemgetter(1))\n",
    "    return index\n",
    "\n",
    "    \n",
    "def get_long_ans():\n",
    "    global null_obj\n",
    "    global test_data\n",
    "    global matched_doc\n",
    "#     print(\"train data \"+str(train_data))\n",
    "    for idx,test_que in enumerate(test_data):\n",
    "        query=test_que['question_text']\n",
    "        url=test_que['document_url']\n",
    "        if url in train_data:\n",
    "            matched_doc = matched_doc+1\n",
    "            answer_obj=train_data[url]\n",
    "#             print(\"size is \"+str(len(answer_obj)))\n",
    "            all_text=[]\n",
    "            print(answer_obj)\n",
    "            for i in range(len(answer_obj)):\n",
    "                all_text.append(answer_obj[i]['text'])\n",
    "            print(all_text)\n",
    "            if(len(all_text)>0):\n",
    "                vectorizer = TfidfVectorizer(stop_words=None)\n",
    "                train_vector = vectorizer.fit_transform(all_text)\n",
    "                query_vector = vectorizer.transform([query])\n",
    "                closest_index=get_closest_document_index(train_vector,query_vector)\n",
    "                h_function(answer_obj[closest_index]['annotations'],test_que['annotations'])\n",
    "                    \n",
    "            else:\n",
    "                h_function(null_obj,test_que['annotations'])        \n",
    "        else:\n",
    "            h_function(null_obj,test_que['annotations'])\n",
    "        \n",
    "    print (matched_doc)\n",
    "    \n",
    "    \n",
    "def h_function(predicted_answer,annotator_answer):\n",
    "    \n",
    "#     print(\"Predicted ans : \" + str(predicted_answer))\n",
    "#     print(\"Annotated ans : \" + str(annotator_answer))\n",
    "    \n",
    "    match_flag = 0\n",
    "    g_count = 0\n",
    "    global true_pos\n",
    "    global true_neg\n",
    "    global recall_den\n",
    "    global precision_den\n",
    "\n",
    "    for i in range(no_of_annotators):\n",
    "        if(annotator_answer[i]['long_answer']['candidate_index'] != -1):\n",
    "            g_count = g_count+1\n",
    "    \n",
    "    if(g_count>=beta):\n",
    "        recall_den=recall_den+1\n",
    "    \n",
    "    if(predicted_answer['candidate_index']!=-1):\n",
    "        precision_den=precision_den+1\n",
    "    \n",
    "    if(predicted_answer['candidate_index']!=-1 and g_count >=beta):\n",
    "        for i in range(no_of_annotators):               \n",
    "            if(annotator_answer[i]['long_answer']['candidate_index'] == predicted_answer['candidate_index'] and \\\n",
    "               annotator_answer[i]['long_answer']['end_byte'] == predicted_answer['end_byte'] and \\\n",
    "               annotator_answer[i]['long_answer']['end_token'] == predicted_answer['end_token'] and \\\n",
    "               annotator_answer[i]['long_answer']['start_byte'] == predicted_answer['start_byte'] and\\\n",
    "               annotator_answer[i]['long_answer']['start_token'] == predicted_answer['start_token']):\n",
    "                match_flag=1\n",
    "                true_pos=true_pos+1\n",
    "                print(\"first!!\")\n",
    "                return 1\n",
    "        if(match_flag==0):\n",
    "            print(\"second!!\")\n",
    "            return 0\n",
    "            \n",
    "            \n",
    "    elif(g_count < beta and predicted_answer['candidate_index']==-1):\n",
    "        true_neg=true_neg+1\n",
    "        print(\"third!!\")\n",
    "        print(\"Predicted ans : \" + str(predicted_answer))\n",
    "        print(\"Annotated ans : \" + str(annotator_answer))\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        print(\"fourth!!\")\n",
    "        return 0\n",
    "        \n",
    "def f1_score():\n",
    "    recall=true_pos/recall_den\n",
    "    \n",
    "    print(\"recall \"+ str(recall))\n",
    "    \n",
    "    precision=true_pos/precision_den\n",
    "    \n",
    "    print(\"Precision \"+ str(precision))\n",
    "    \n",
    "    if(precision!=0 and recall!=0):\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "    else:\n",
    "        f1=0\n",
    "    print(\"F1 Score \"+ str(f1))\n",
    "       \n",
    "    print(\"true_pos \"+str(true_pos))\n",
    "    print(\"true_neg \"+str(true_neg))\n",
    "    print(\"recall_den \"+str(recall_den))\n",
    "    print(\"precision_den \"+str(precision_den))\n",
    "\n",
    "        \n",
    "def main():\n",
    "       \n",
    "    print (\"Start time\")\n",
    "    currentDT1 = datetime.datetime.now()\n",
    "    print (str(currentDT1))\n",
    "\n",
    "    global test_data\n",
    "    test_data=get_test_data()\n",
    "    \n",
    "    global train_data\n",
    "    create_url_dict()\n",
    "    \n",
    "    get_long_ans()\n",
    "    f1_score()\n",
    "\n",
    "    print (\"End time\")\n",
    "    currentDT2 = datetime.datetime.now()\n",
    "    print (str(currentDT2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nq_env",
   "language": "python",
   "name": "nq_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
