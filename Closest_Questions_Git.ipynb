{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import operator\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import datetime\n",
    "\n",
    "\n",
    "train_dir_path='/home/irlplab/Documents/Share/Akansha/GoogleNLQ/natural_questions/v1.0/train/'\n",
    "test_dir_path='/home/irlplab/Documents/Share/Akansha/GoogleNLQ/natural_questions/v1.0/dev/'\n",
    "# test_dir_path='/home/irlplab/Documents/Share/Akansha/temp/test/'\n",
    "# train_dir_path='/home/irlplab/Documents/Share/Akansha/temp/train/'\n",
    "\n",
    "answer_candidate = []\n",
    "long_answer={}\n",
    "train_questions=[]\n",
    "test_questions=[]\n",
    "beta = 2\n",
    "true_pos=0\n",
    "true_neg=0\n",
    "recall_den=0\n",
    "precision_den=0\n",
    "\n",
    "\n",
    "def load_json_multiple(segments):\n",
    "    chunk = \"\"\n",
    "    for segment in segments:\n",
    "        \n",
    "        chunk += segment\n",
    "        try:\n",
    "            yield json.loads(chunk)\n",
    "            chunk = \"\"\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "def get_predicted_answer(segments,example_id):\n",
    "    for segment in segments:\n",
    "        ex_object = json.loads(segment)\n",
    "        print(ex_object['example_id'])\n",
    "        \n",
    "        if(ex_object['example_id'] == example_id):\n",
    "            return ex_object['annotations'][0]['long_answer']\n",
    "        \n",
    "\n",
    "def get_train_data():\n",
    "    json_files = [pos_json for pos_json in os.listdir(train_dir_path) if pos_json.endswith('.jsonl')]\n",
    "    all_data=[]\n",
    "      \n",
    "    for index, js in enumerate(json_files):\n",
    "        with open(os.path.join(train_dir_path, js)) as json_file:\n",
    "            for parsed_json in load_json_multiple(json_file):\n",
    "                data = {}\n",
    "                data[\"example_id\"]=parsed_json['example_id']\n",
    "                data[\"question_text\"]=parsed_json['question_text']\n",
    "                data[\"file_name\"]=js\n",
    "                data[\"document_url\"]=parsed_json['document_url']\n",
    "                all_data.append(data)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def get_test_data():\n",
    "    json_files = [pos_json for pos_json in os.listdir(test_dir_path) if pos_json.endswith('.jsonl')]\n",
    "    all_data=[]\n",
    "\n",
    "     \n",
    "    for index, js in enumerate(json_files):\n",
    "        with open(os.path.join(test_dir_path, js)) as json_file:\n",
    "            for parsed_json in load_json_multiple(json_file):\n",
    "                data = {}\n",
    "                data[\"example_id\"]=parsed_json['example_id']\n",
    "                data[\"question_text\"]=parsed_json['question_text']\n",
    "                data[\"file_name\"]=js\n",
    "                data[\"annotations\"]=parsed_json['annotations']\n",
    "                data[\"document_url\"]=parsed_json['document_url']\n",
    "                all_data.append(data)\n",
    "                \n",
    "               \n",
    "    return all_data\n",
    "\n",
    "\n",
    "def get_closest_document_index(train_vector,query_vector):\n",
    "    \n",
    "    cosine_similarities = linear_kernel(query_vector, train_vector).flatten()\n",
    "    index, value = max(enumerate(cosine_similarities), key=operator.itemgetter(1))\n",
    "    example_id = train_questions[index]['example_id']\n",
    "    f_name = train_questions[index]['file_name']\n",
    "    doc_url = train_questions[index]['document_url']\n",
    "    return example_id,f_name,doc_url\n",
    "\n",
    "    \n",
    "\n",
    "#check if long answer is null or not\n",
    "def f_predicted_l():\n",
    "    candidate_index=long_answer[\"candidate_index\"]\n",
    "    if(candidate_index==-1):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "      \n",
    "\n",
    "def get_annotator_answer(idx):\n",
    "    annotator_answer = []\n",
    "    test_obj = test_questions[idx]['annotations']\n",
    "    for i in range(5):\n",
    "        annotator_answer.append(test_obj[i]['long_answer'])\n",
    "    return annotator_answer\n",
    "            \n",
    "    \n",
    "    \n",
    "def h_function(predicted_answer,annotator_answer):\n",
    "    match_flag = 0\n",
    "    g_count = 0\n",
    "    global true_pos\n",
    "    global true_neg\n",
    "    global recall_den\n",
    "    global precision_den\n",
    "    print(predicted_answer)\n",
    "    print (annotator_answer)\n",
    "    for i in range(5):\n",
    "        if(annotator_answer[i]['candidate_index'] != -1):\n",
    "            g_count = g_count+1\n",
    "    \n",
    "    if(g_count>=beta):\n",
    "        recall_den=recall_den+1\n",
    "    \n",
    "    if(predicted_answer['candidate_index']!=-1):\n",
    "        precision_den=precision_den+1\n",
    "    \n",
    "    if(predicted_answer['candidate_index']!=-1 and g_count >=beta):\n",
    "        for i in range(5):               \n",
    "            if(annotator_answer[i]['candidate_index'] == predicted_answer['candidate_index'] and \\\n",
    "               annotator_answer[i]['end_byte'] == predicted_answer['end_byte'] and \\\n",
    "               annotator_answer[i]['end_token'] == predicted_answer['end_token'] and \\\n",
    "               annotator_answer[i]['start_byte'] == predicted_answer['start_byte'] and\\\n",
    "               annotator_answer[i]['start_token'] == predicted_answer['start_token']):\n",
    "                match_flag=1\n",
    "                true_pos=true_pos+1\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "    elif(g_count < beta and predicted_answer['candidate_index']==-1):\n",
    "        true_neg=true_neg+1\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "\n",
    "def f1_score():\n",
    "    recall=true_pos/recall_den\n",
    "    \n",
    "    print(\"recall \"+ str(recall))\n",
    "    \n",
    "    precision=true_pos/precision_den\n",
    "    \n",
    "    print(\"Precision \"+ str(precision))\n",
    "    \n",
    "    if(precision!=0 and recall!=0):\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "    else:\n",
    "        f1=0\n",
    "    print(\"F1 Score \"+ str(f1))\n",
    "       \n",
    "\n",
    "    \n",
    "def get_long_ans_id():\n",
    "    all_questions=[]\n",
    "    l_candidate=[]\n",
    "    for idx, train_question in enumerate(train_questions):\n",
    "        all_questions.append(train_question[\"question_text\"])\n",
    "    vectorizer = TfidfVectorizer(stop_words=None)\n",
    "    train_vector = vectorizer.fit_transform(all_questions)\n",
    "    for idx,test_question in enumerate(test_questions):\n",
    "        query=test_question['question_text']\n",
    "        query_vector = vectorizer.transform([query])\n",
    "        e_id,f_name,doc_url=get_closest_document_index(train_vector,query_vector)\n",
    "        data={}\n",
    "        data['example_id']=e_id\n",
    "        data['file_name']=f_name\n",
    "        data['document_url']=doc_url\n",
    "        l_candidate.append(data)\n",
    "    return l_candidate\n",
    " \n",
    "def get_long_ans(l_candidates):\n",
    "    for idx,l_candidate in enumerate(l_candidates):\n",
    "        pred_url=l_candidate['document_url']\n",
    "        actual_url=test_questions[idx]['document_url']\n",
    "        print(\"pred url\"+pred_url)\n",
    "        print(\"actual url\"+actual_url)\n",
    "        if(pred_url==actual_url):\n",
    "            print(\"inside if\")\n",
    "            #get long answer from example_id->filename\n",
    "            #compare it with actual answers\n",
    "            file_name=l_candidate['file_name']\n",
    "            with open(os.path.join(train_dir_path, file_name)) as json_file:\n",
    "                predicted_answer = get_predicted_answer(json_file,l_candidate['example_id'])\n",
    "            annotator_answer = get_annotator_answer(idx)\n",
    "            h_value = h_function(predicted_answer,annotator_answer)\n",
    "            print(\"h value = \"+ str(h_value))\n",
    "            \n",
    "        else:\n",
    "            #SET LONG ANSWER AS NULL\n",
    "            print (\"Mis-matched url\")\n",
    "        \n",
    "def main():\n",
    "       \n",
    "    print (\"Start time\")\n",
    "    currentDT1 = datetime.datetime.now()\n",
    "    print (str(currentDT1))\n",
    "\n",
    "    global train_questions\n",
    "    train_questions=get_train_data()\n",
    "    \n",
    "    global test_questions\n",
    "    test_questions=get_test_data()\n",
    "    \n",
    "    l_candidate = get_long_ans_id()\n",
    "  \n",
    "    \n",
    "    get_long_ans(l_candidate)\n",
    "    \n",
    "    f1_score()\n",
    "\n",
    "    print (\"End time\")\n",
    "    currentDT2 = datetime.datetime.now()\n",
    "    print (str(currentDT2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
